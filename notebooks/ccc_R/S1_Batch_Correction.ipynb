{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d3b3320",
   "metadata": {},
   "source": [
    "For use with Tensor-cell2cell, we want a dataset that represents >2 contexts. We also want a dataset that contains [replicates](https://www.nature.com/articles/nmeth.3091). Replicates will allow us to ensure that the output factors are not simply due to technical effects (i.e., a factor with high loadings for just one replicate in the context dimension). We will use a [BALF COVID dataset](https://doi.org/10.1038/s41591-020-0901-9), which contains 12 samples associated with \"Healthy Control\", \"Moderate\", or \"Severe\" COVID contexts. This dataset does not contain technical replicates since each sample was taken from a different patient, but each sample associated with a context is a biological replicate. \n",
    "\n",
    "[Batch correction](https://www.nature.com/articles/s41592-018-0254-1) removes technical variation while preserving biological variation between samples. We can reasonably assume that the biological variation in samples between contexts will be greater than that of those within contexts after using appropriate batch correction to remove technical variation. Thus, we expect Tensor-cell2cell to capture overall communication trends differing between contexts and can then assess that output factors aren't simply due to technical effects by checking that the output factors have similar loadings for biological replicates and do not have  high loadings for just one sample in the context dimension. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d8f284",
   "metadata": {},
   "source": [
    "Finally, we apply a batch correction. The goal here is to account for sample-to-sample technical variability. \n",
    "\n",
    "At this point, we diverge from the Python preprocessing tutorial in order to leverage Seurat's built-in batch correction functions. To decrease run time, we will use reciprocal PCA instead of CCA. See https://satijalab.org/seurat/articles/integration_introduction.html and Seurat's other integration vignettes for additional details. To apply Combat as in scanpy, see commented code further below.\n",
    "\n",
    "Note, the final input matrices to Tensor-cell2cell must be non-negative. We will demonstrate workarounds to negative counts in the tensor building tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72a33ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.var <- 'Sample.ID' # the batch variable in the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21537527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the HVGs for each sample separately\n",
    "balf.samples <- lapply(balf.samples, \n",
    "                      function(so) FindVariableFeatures(so, selection.method = \"vst\", nfeatures = 2000))\n",
    "                       \n",
    "# find the common HVGs across samples\n",
    "integration.features <- SelectIntegrationFeatures(object.list = balf.samples)\n",
    "\n",
    "                       \n",
    "# # to use CCA instead of reciprocal PCA, follow lines 10-12, instead of lines 14-22\n",
    "# # find the integration anchors\n",
    "# integration.anchors <- FindIntegrationAnchors(object.list = balf.samples, \n",
    "#                                               anchor.features = integration.features)    \n",
    "                       \n",
    "# calculate PCA on each sample separately\n",
    "balf.samples <- lapply(X = balf.samples, FUN = function(x) {\n",
    "    x <- ScaleData(x, features = integration.features, verbose = F)\n",
    "    x <- RunPCA(x, features = integration.features, verbose = F)\n",
    "})\n",
    "\n",
    "# find the integration anchors\n",
    "integration.anchors <- FindIntegrationAnchors(object.list = balf.samples, \n",
    "                                              anchor.features = integration.features, reduction = \"rpca\")\n",
    "\n",
    "# do the batch correction\n",
    "balf.corrected <- IntegrateData(anchorset = integration.anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a655350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2000 top variable features were already calculated\n",
    "\n",
    "# get PCA to 100 PCs\n",
    "balf.corrected <- ScaleData(balf.corrected, verbose = F)\n",
    "balf.corrected <- RunPCA(balf.corrected, npcs = 100, verbose = F)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [conda env:ccc_protocols]",
   "language": "R",
   "name": "conda-env-ccc_protocols-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
