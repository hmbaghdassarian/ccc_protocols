{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df4e55f4",
   "metadata": {},
   "source": [
    "This tutorial will demonstrate how to pre-process single-cell raw UMI counts to generate expression matrices that can be used as input to cell-cell communication tools. We will assume appropriate quality-control (QC) has already been applied to the dataset (e.g., exclusion of low-quality cells and doublets). We recommend the tutorial by [Luecken & Theis](https://doi.org/10.15252/msb.20188746) as a starting point for a detailed overview of QC and single-cell RNAseq analysis pipelines in general. \n",
    "\n",
    "Here we will focus on:\n",
    "1. Normalization\n",
    "2. Batch correction (for multiple samples/contexts)\n",
    "\n",
    "We demonstrate a typical workflow using the popular single-cell analysis [Seurat](https://satijalab.org/seurat/index.html). Preferably, the workflow can maintain non-negative counts since Tensor-cell2cell uses a non-negative decomposition.\n",
    "\n",
    "For use with Tensor-cell2cell, we want a dataset that represents >2 contexts. We also want a dataset that contains [replicates](https://www.nature.com/articles/nmeth.3091). Replicates will allow us to ensure that the output factors are not simply due to technical effects (i.e., a factor with high loadings for just one replicate in the context dimension). We will use a [BALF COVID dataset](https://doi.org/10.1038/s41591-020-0901-9), which contains 12 samples associated with \"Healthy Control\", \"Moderate\", or \"Severe\" COVID contexts. This dataset does not contain technical replicates since each sample was taken from a different patient, but each sample associated with a context is a biological replicate. [Batch correction](https://www.nature.com/articles/s41592-018-0254-1) removes technical variation while preserving biological variation bewteen samples. We can reasonably assume that the biological variation in samples between contexts will be greater than that of those within contexts after using appropriate batch correction to remove technical variation. Thus, we expect Tensor-cell2cell to capture overall communication trends differing between contexts and can then assess that output factors aren't simply due to technical effects by checking that the output factors have similar loadings for biological replicates and do not have  high loadings for just one sample in the context dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106218d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching SeuratObject\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(Seurat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0e5a63",
   "metadata": {},
   "source": [
    "The 12 samples can be downloaded as .h5 files from [here](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE145926). You can also download the cell metadata from [here](https://raw.githubusercontent.com/zhangzlab/covid_balf/master/all.cell.annotation.meta.txt)\n",
    "\n",
    "We download these files directly in the proceeding cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80279064",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.path<-'/data3/hratch/ccc_protocols/raw/covid_balf/'\n",
    "\n",
    "# download the metadata\n",
    "metadata.link <- 'https://raw.githubusercontent.com/zhangzlab/covid_balf/master/all.cell.annotation.meta.txt'\n",
    "cmd <- paste0('wget ', metadata.link, ' -O ', data.path, 'metadata.txt')\n",
    "system(cmd, ignore.stdout = T, ignore.stderr = T)\n",
    "\n",
    "# download the expression data\n",
    "sample.links <- c(\n",
    "    'https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM4339nnn/GSM4339769/suppl/GSM4339769%5FC141%5Ffiltered%5Ffeature%5Fbc%5Fmatrix%2Eh5',\n",
    "    'https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM4339nnn/GSM4339770/suppl/GSM4339770%5FC142%5Ffiltered%5Ffeature%5Fbc%5Fmatrix%2Eh5',\n",
    "    'https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM4339nnn/GSM4339771/suppl/GSM4339771%5FC143%5Ffiltered%5Ffeature%5Fbc%5Fmatrix%2Eh5', \n",
    "    'https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM4339nnn/GSM4339772/suppl/GSM4339772%5FC144%5Ffiltered%5Ffeature%5Fbc%5Fmatrix%2Eh5', \n",
    "    'https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM4339nnn/GSM4339773/suppl/GSM4339773%5FC145%5Ffiltered%5Ffeature%5Fbc%5Fmatrix%2Eh5',\n",
    "    'https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM4339nnn/GSM4339774/suppl/GSM4339774%5FC146%5Ffiltered%5Ffeature%5Fbc%5Fmatrix%2Eh5', \n",
    "    'https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM4475nnn/GSM4475048/suppl/GSM4475048%5FC51%5Ffiltered%5Ffeature%5Fbc%5Fmatrix%2Eh5', \n",
    "    'https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM4475nnn/GSM4475049/suppl/GSM4475049%5FC52%5Ffiltered%5Ffeature%5Fbc%5Fmatrix%2Eh5', \n",
    "    'https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM4475nnn/GSM4475050/suppl/GSM4475050%5FC100%5Ffiltered%5Ffeature%5Fbc%5Fmatrix%2Eh5', \n",
    "    'https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM4475nnn/GSM4475051/suppl/GSM4475051%5FC148%5Ffiltered%5Ffeature%5Fbc%5Fmatrix%2Eh5', \n",
    "    'https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM4475nnn/GSM4475052/suppl/GSM4475052%5FC149%5Ffiltered%5Ffeature%5Fbc%5Fmatrix%2Eh5',\n",
    "    'https://ftp.ncbi.nlm.nih.gov/geo/samples/GSM4475nnn/GSM4475053/suppl/GSM4475053%5FC152%5Ffiltered%5Ffeature%5Fbc%5Fmatrix%2Eh5'\n",
    "    )\n",
    "\n",
    "for (sl in sample.links){\n",
    "    cmd <- paste0('wget ', sl, ' -P ', data.path)\n",
    "    system(cmd, ignore.stdout = T, ignore.stderr = T)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa3d2b1",
   "metadata": {},
   "source": [
    "We can then format the downloaded files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdbdb59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Sample.ID</th><th scope=col>sample_new</th><th scope=col>Context</th><th scope=col>disease</th><th scope=col>hasnCoV</th><th scope=col>cluster</th><th scope=col>cell.type</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>AAACCCACAGCTACAT_3</th><td>C100</td><td>HC3</td><td>Healthy.Control</td><td>N</td><td>N</td><td>27</td><td>B          </td></tr>\n",
       "\t<tr><th scope=row>AAACCCATCCACGGGT_3</th><td>C100</td><td>HC3</td><td>Healthy.Control</td><td>N</td><td>N</td><td>23</td><td>Macrophages</td></tr>\n",
       "\t<tr><th scope=row>AAACCCATCCCATTCG_3</th><td>C100</td><td>HC3</td><td>Healthy.Control</td><td>N</td><td>N</td><td> 6</td><td>T          </td></tr>\n",
       "\t<tr><th scope=row>AAACGAACAAACAGGC_3</th><td>C100</td><td>HC3</td><td>Healthy.Control</td><td>N</td><td>N</td><td>10</td><td>Macrophages</td></tr>\n",
       "\t<tr><th scope=row>AAACGAAGTCGCACAC_3</th><td>C100</td><td>HC3</td><td>Healthy.Control</td><td>N</td><td>N</td><td>10</td><td>Macrophages</td></tr>\n",
       "\t<tr><th scope=row>AAACGAAGTCTATGAC_3</th><td>C100</td><td>HC3</td><td>Healthy.Control</td><td>N</td><td>N</td><td> 9</td><td>T          </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 7\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & Sample.ID & sample\\_new & Context & disease & hasnCoV & cluster & cell.type\\\\\n",
       "  & <chr> & <chr> & <fct> & <chr> & <chr> & <int> & <chr>\\\\\n",
       "\\hline\n",
       "\tAAACCCACAGCTACAT\\_3 & C100 & HC3 & Healthy.Control & N & N & 27 & B          \\\\\n",
       "\tAAACCCATCCACGGGT\\_3 & C100 & HC3 & Healthy.Control & N & N & 23 & Macrophages\\\\\n",
       "\tAAACCCATCCCATTCG\\_3 & C100 & HC3 & Healthy.Control & N & N &  6 & T          \\\\\n",
       "\tAAACGAACAAACAGGC\\_3 & C100 & HC3 & Healthy.Control & N & N & 10 & Macrophages\\\\\n",
       "\tAAACGAAGTCGCACAC\\_3 & C100 & HC3 & Healthy.Control & N & N & 10 & Macrophages\\\\\n",
       "\tAAACGAAGTCTATGAC\\_3 & C100 & HC3 & Healthy.Control & N & N &  9 & T          \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 7\n",
       "\n",
       "| <!--/--> | Sample.ID &lt;chr&gt; | sample_new &lt;chr&gt; | Context &lt;fct&gt; | disease &lt;chr&gt; | hasnCoV &lt;chr&gt; | cluster &lt;int&gt; | cell.type &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| AAACCCACAGCTACAT_3 | C100 | HC3 | Healthy.Control | N | N | 27 | B           |\n",
       "| AAACCCATCCACGGGT_3 | C100 | HC3 | Healthy.Control | N | N | 23 | Macrophages |\n",
       "| AAACCCATCCCATTCG_3 | C100 | HC3 | Healthy.Control | N | N |  6 | T           |\n",
       "| AAACGAACAAACAGGC_3 | C100 | HC3 | Healthy.Control | N | N | 10 | Macrophages |\n",
       "| AAACGAAGTCGCACAC_3 | C100 | HC3 | Healthy.Control | N | N | 10 | Macrophages |\n",
       "| AAACGAAGTCTATGAC_3 | C100 | HC3 | Healthy.Control | N | N |  9 | T           |\n",
       "\n"
      ],
      "text/plain": [
       "                   Sample.ID sample_new Context         disease hasnCoV cluster\n",
       "AAACCCACAGCTACAT_3 C100      HC3        Healthy.Control N       N       27     \n",
       "AAACCCATCCACGGGT_3 C100      HC3        Healthy.Control N       N       23     \n",
       "AAACCCATCCCATTCG_3 C100      HC3        Healthy.Control N       N        6     \n",
       "AAACGAACAAACAGGC_3 C100      HC3        Healthy.Control N       N       10     \n",
       "AAACGAAGTCGCACAC_3 C100      HC3        Healthy.Control N       N       10     \n",
       "AAACGAAGTCTATGAC_3 C100      HC3        Healthy.Control N       N        9     \n",
       "                   cell.type  \n",
       "AAACCCACAGCTACAT_3 B          \n",
       "AAACCCATCCACGGGT_3 Macrophages\n",
       "AAACCCATCCCATTCG_3 T          \n",
       "AAACGAACAAACAGGC_3 Macrophages\n",
       "AAACGAAGTCGCACAC_3 Macrophages\n",
       "AAACGAAGTCTATGAC_3 T          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# format the metadata\n",
    "md <- read.table(paste0(data.path, 'metadata.txt'), header = T, row.names = 'ID')\n",
    "colnames(md) = c('Sample.ID', 'sample_new', 'Context', 'disease', 'hasnCoV', 'cluster', 'cell.type')\n",
    "\n",
    "context.map = c('Healthy.Control', 'Moderate.Covid', 'Severe.Covid')\n",
    "names(context.map) <- c('HC', 'M', 'S')\n",
    "md['Context'] <- unname(context.map[md$Context])\n",
    "md$Context <- factor(md$Context, levels = c('Healthy.Control', 'Moderate.Covid', 'Severe.Covid'))\n",
    "\n",
    "md<-md[md$Sample.ID != 'GSM3660650', ] # drop the non-scRNAseq dataset included in this file\n",
    "\n",
    "md<-md[with(md, order(Context, Sample.ID)), ]\n",
    "head(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a327438",
   "metadata": {},
   "outputs": [],
   "source": [
    "balf.samples<-list()\n",
    "\n",
    "suppressMessages({\n",
    "    suppressWarnings({\n",
    "        for (filename in list.files(data.path)){\n",
    "            if (endsWith(filename, '.h5')){\n",
    "                sample<-unlist(strsplit(filename, '_'))[[2]]\n",
    "\n",
    "                # subset and format metadata\n",
    "                md.sample<-md[md$Sample.ID == sample,]\n",
    "                rownames(md.sample) <- unname(sapply(rownames(md.sample), \n",
    "                                                   function(x) paste0(unlist(strsplit(x, '_'))[[1]], '-1')))\n",
    "                # load the counts\n",
    "                so <- Seurat::Read10X_h5(filename=paste0(data.path, filename), unique.features=T)\n",
    "                so <- so[, rownames(md.sample)] # only include cells present in the metadata\n",
    "\n",
    "                # preprocess\n",
    "                so <- CreateSeuratObject(counts=so, project=sample, meta.data=md.sample[c('Sample.ID', 'Context', 'cell.type')], \n",
    "                                          min.cells=3)        \n",
    "                balf.samples[[sample]] <- so\n",
    "            }\n",
    "        }        \n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74c3be4",
   "metadata": {},
   "source": [
    "balf.samples is a list with names as each sample and values as a Seurat object storing the raw UMI counts for that sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6dcdcd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'C141'</li><li>'C142'</li><li>'C143'</li><li>'C144'</li><li>'C145'</li><li>'C146'</li><li>'C51'</li><li>'C52'</li><li>'C100'</li><li>'C148'</li><li>'C149'</li><li>'C152'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'C141'\n",
       "\\item 'C142'\n",
       "\\item 'C143'\n",
       "\\item 'C144'\n",
       "\\item 'C145'\n",
       "\\item 'C146'\n",
       "\\item 'C51'\n",
       "\\item 'C52'\n",
       "\\item 'C100'\n",
       "\\item 'C148'\n",
       "\\item 'C149'\n",
       "\\item 'C152'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'C141'\n",
       "2. 'C142'\n",
       "3. 'C143'\n",
       "4. 'C144'\n",
       "5. 'C145'\n",
       "6. 'C146'\n",
       "7. 'C51'\n",
       "8. 'C52'\n",
       "9. 'C100'\n",
       "10. 'C148'\n",
       "11. 'C149'\n",
       "12. 'C152'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"C141\" \"C142\" \"C143\" \"C144\" \"C145\" \"C146\" \"C51\"  \"C52\"  \"C100\" \"C148\"\n",
       "[11] \"C149\" \"C152\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(balf.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f3dfaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "An object of class Seurat \n",
       "16566 features across 2566 samples within 1 assay \n",
       "Active assay: RNA (16566 features, 0 variable features)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "balf.samples$C100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf64480",
   "metadata": {},
   "source": [
    "To normalize the raw UMI counts, we recommend log(1+CPM) normalization, as this maintains non-negative counts and is the input for many communication scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83b48da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "balf.samples <- lapply(balf.samples, \n",
    "                    function(so) NormalizeData(so, normalization.method = \"LogNormalize\", scale.factor = 1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17994ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 2566</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>AAACCCACAGCTACAT-1</th><th scope=col>AAACCCATCCACGGGT-1</th><th scope=col>AAACCCATCCCATTCG-1</th><th scope=col>AAACGAACAAACAGGC-1</th><th scope=col>AAACGAAGTCGCACAC-1</th><th scope=col>AAACGAAGTCTATGAC-1</th><th scope=col>AAACGAAGTGTAGTGG-1</th><th scope=col>AAACGCTGTCACGTGC-1</th><th scope=col>AAACGCTGTTGGAGGT-1</th><th scope=col>AAAGAACTCTAGAACC-1</th><th scope=col>⋯</th><th scope=col>TTTGATCTCCCGAAAT-1</th><th scope=col>TTTGGAGCAATACAGA-1</th><th scope=col>TTTGGAGTCACCATAG-1</th><th scope=col>TTTGGAGTCTCACCCA-1</th><th scope=col>TTTGGTTAGATGGCGT-1</th><th scope=col>TTTGGTTGTACCCAGC-1</th><th scope=col>TTTGGTTGTTACTCAG-1</th><th scope=col>TTTGTTGAGCTAGAGC-1</th><th scope=col>TTTGTTGCAATGAAAC-1</th><th scope=col>TTTGTTGCAGAGGGTT-1</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>AL627309.1</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.000000</td><td>0</td><td>0.000000</td><td>0</td><td>⋯</td><td>0</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.00000</td><td>0.000000</td><td>0</td><td>0.000000</td><td>0</td><td>0.000000</td></tr>\n",
       "\t<tr><th scope=row>AL669831.5</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.000000</td><td>0</td><td>0.000000</td><td>0</td><td>⋯</td><td>0</td><td>0.000000</td><td>0.000000</td><td>4.286483</td><td>0.00000</td><td>0.000000</td><td>0</td><td>4.220721</td><td>0</td><td>0.000000</td></tr>\n",
       "\t<tr><th scope=row>FAM87B</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.000000</td><td>0</td><td>0.000000</td><td>0</td><td>⋯</td><td>0</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.00000</td><td>0.000000</td><td>0</td><td>0.000000</td><td>0</td><td>0.000000</td></tr>\n",
       "\t<tr><th scope=row>LINC00115</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.000000</td><td>0</td><td>0.000000</td><td>0</td><td>⋯</td><td>0</td><td>0.000000</td><td>4.040861</td><td>0.000000</td><td>5.81081</td><td>0.000000</td><td>0</td><td>4.906497</td><td>0</td><td>0.000000</td></tr>\n",
       "\t<tr><th scope=row>FAM41C</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.000000</td><td>0</td><td>0.000000</td><td>0</td><td>⋯</td><td>0</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.00000</td><td>0.000000</td><td>0</td><td>0.000000</td><td>0</td><td>0.000000</td></tr>\n",
       "\t<tr><th scope=row>NOC2L</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>5.683571</td><td>0</td><td>5.199611</td><td>0</td><td>⋯</td><td>0</td><td>6.326213</td><td>0.000000</td><td>0.000000</td><td>0.00000</td><td>5.041668</td><td>0</td><td>4.220721</td><td>0</td><td>4.216369</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2566\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & AAACCCACAGCTACAT-1 & AAACCCATCCACGGGT-1 & AAACCCATCCCATTCG-1 & AAACGAACAAACAGGC-1 & AAACGAAGTCGCACAC-1 & AAACGAAGTCTATGAC-1 & AAACGAAGTGTAGTGG-1 & AAACGCTGTCACGTGC-1 & AAACGCTGTTGGAGGT-1 & AAAGAACTCTAGAACC-1 & ⋯ & TTTGATCTCCCGAAAT-1 & TTTGGAGCAATACAGA-1 & TTTGGAGTCACCATAG-1 & TTTGGAGTCTCACCCA-1 & TTTGGTTAGATGGCGT-1 & TTTGGTTGTACCCAGC-1 & TTTGGTTGTTACTCAG-1 & TTTGTTGAGCTAGAGC-1 & TTTGTTGCAATGAAAC-1 & TTTGTTGCAGAGGGTT-1\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\tAL627309.1 & 0 & 0 & 0 & 0 & 0 & 0 & 0.000000 & 0 & 0.000000 & 0 & ⋯ & 0 & 0.000000 & 0.000000 & 0.000000 & 0.00000 & 0.000000 & 0 & 0.000000 & 0 & 0.000000\\\\\n",
       "\tAL669831.5 & 0 & 0 & 0 & 0 & 0 & 0 & 0.000000 & 0 & 0.000000 & 0 & ⋯ & 0 & 0.000000 & 0.000000 & 4.286483 & 0.00000 & 0.000000 & 0 & 4.220721 & 0 & 0.000000\\\\\n",
       "\tFAM87B & 0 & 0 & 0 & 0 & 0 & 0 & 0.000000 & 0 & 0.000000 & 0 & ⋯ & 0 & 0.000000 & 0.000000 & 0.000000 & 0.00000 & 0.000000 & 0 & 0.000000 & 0 & 0.000000\\\\\n",
       "\tLINC00115 & 0 & 0 & 0 & 0 & 0 & 0 & 0.000000 & 0 & 0.000000 & 0 & ⋯ & 0 & 0.000000 & 4.040861 & 0.000000 & 5.81081 & 0.000000 & 0 & 4.906497 & 0 & 0.000000\\\\\n",
       "\tFAM41C & 0 & 0 & 0 & 0 & 0 & 0 & 0.000000 & 0 & 0.000000 & 0 & ⋯ & 0 & 0.000000 & 0.000000 & 0.000000 & 0.00000 & 0.000000 & 0 & 0.000000 & 0 & 0.000000\\\\\n",
       "\tNOC2L & 0 & 0 & 0 & 0 & 0 & 0 & 5.683571 & 0 & 5.199611 & 0 & ⋯ & 0 & 6.326213 & 0.000000 & 0.000000 & 0.00000 & 5.041668 & 0 & 4.220721 & 0 & 4.216369\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2566\n",
       "\n",
       "| <!--/--> | AAACCCACAGCTACAT-1 &lt;dbl&gt; | AAACCCATCCACGGGT-1 &lt;dbl&gt; | AAACCCATCCCATTCG-1 &lt;dbl&gt; | AAACGAACAAACAGGC-1 &lt;dbl&gt; | AAACGAAGTCGCACAC-1 &lt;dbl&gt; | AAACGAAGTCTATGAC-1 &lt;dbl&gt; | AAACGAAGTGTAGTGG-1 &lt;dbl&gt; | AAACGCTGTCACGTGC-1 &lt;dbl&gt; | AAACGCTGTTGGAGGT-1 &lt;dbl&gt; | AAAGAACTCTAGAACC-1 &lt;dbl&gt; | ⋯ ⋯ | TTTGATCTCCCGAAAT-1 &lt;dbl&gt; | TTTGGAGCAATACAGA-1 &lt;dbl&gt; | TTTGGAGTCACCATAG-1 &lt;dbl&gt; | TTTGGAGTCTCACCCA-1 &lt;dbl&gt; | TTTGGTTAGATGGCGT-1 &lt;dbl&gt; | TTTGGTTGTACCCAGC-1 &lt;dbl&gt; | TTTGGTTGTTACTCAG-1 &lt;dbl&gt; | TTTGTTGAGCTAGAGC-1 &lt;dbl&gt; | TTTGTTGCAATGAAAC-1 &lt;dbl&gt; | TTTGTTGCAGAGGGTT-1 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| AL627309.1 | 0 | 0 | 0 | 0 | 0 | 0 | 0.000000 | 0 | 0.000000 | 0 | ⋯ | 0 | 0.000000 | 0.000000 | 0.000000 | 0.00000 | 0.000000 | 0 | 0.000000 | 0 | 0.000000 |\n",
       "| AL669831.5 | 0 | 0 | 0 | 0 | 0 | 0 | 0.000000 | 0 | 0.000000 | 0 | ⋯ | 0 | 0.000000 | 0.000000 | 4.286483 | 0.00000 | 0.000000 | 0 | 4.220721 | 0 | 0.000000 |\n",
       "| FAM87B | 0 | 0 | 0 | 0 | 0 | 0 | 0.000000 | 0 | 0.000000 | 0 | ⋯ | 0 | 0.000000 | 0.000000 | 0.000000 | 0.00000 | 0.000000 | 0 | 0.000000 | 0 | 0.000000 |\n",
       "| LINC00115 | 0 | 0 | 0 | 0 | 0 | 0 | 0.000000 | 0 | 0.000000 | 0 | ⋯ | 0 | 0.000000 | 4.040861 | 0.000000 | 5.81081 | 0.000000 | 0 | 4.906497 | 0 | 0.000000 |\n",
       "| FAM41C | 0 | 0 | 0 | 0 | 0 | 0 | 0.000000 | 0 | 0.000000 | 0 | ⋯ | 0 | 0.000000 | 0.000000 | 0.000000 | 0.00000 | 0.000000 | 0 | 0.000000 | 0 | 0.000000 |\n",
       "| NOC2L | 0 | 0 | 0 | 0 | 0 | 0 | 5.683571 | 0 | 5.199611 | 0 | ⋯ | 0 | 6.326213 | 0.000000 | 0.000000 | 0.00000 | 5.041668 | 0 | 4.220721 | 0 | 4.216369 |\n",
       "\n"
      ],
      "text/plain": [
       "           AAACCCACAGCTACAT-1 AAACCCATCCACGGGT-1 AAACCCATCCCATTCG-1\n",
       "AL627309.1 0                  0                  0                 \n",
       "AL669831.5 0                  0                  0                 \n",
       "FAM87B     0                  0                  0                 \n",
       "LINC00115  0                  0                  0                 \n",
       "FAM41C     0                  0                  0                 \n",
       "NOC2L      0                  0                  0                 \n",
       "           AAACGAACAAACAGGC-1 AAACGAAGTCGCACAC-1 AAACGAAGTCTATGAC-1\n",
       "AL627309.1 0                  0                  0                 \n",
       "AL669831.5 0                  0                  0                 \n",
       "FAM87B     0                  0                  0                 \n",
       "LINC00115  0                  0                  0                 \n",
       "FAM41C     0                  0                  0                 \n",
       "NOC2L      0                  0                  0                 \n",
       "           AAACGAAGTGTAGTGG-1 AAACGCTGTCACGTGC-1 AAACGCTGTTGGAGGT-1\n",
       "AL627309.1 0.000000           0                  0.000000          \n",
       "AL669831.5 0.000000           0                  0.000000          \n",
       "FAM87B     0.000000           0                  0.000000          \n",
       "LINC00115  0.000000           0                  0.000000          \n",
       "FAM41C     0.000000           0                  0.000000          \n",
       "NOC2L      5.683571           0                  5.199611          \n",
       "           AAAGAACTCTAGAACC-1 ⋯ TTTGATCTCCCGAAAT-1 TTTGGAGCAATACAGA-1\n",
       "AL627309.1 0                  ⋯ 0                  0.000000          \n",
       "AL669831.5 0                  ⋯ 0                  0.000000          \n",
       "FAM87B     0                  ⋯ 0                  0.000000          \n",
       "LINC00115  0                  ⋯ 0                  0.000000          \n",
       "FAM41C     0                  ⋯ 0                  0.000000          \n",
       "NOC2L      0                  ⋯ 0                  6.326213          \n",
       "           TTTGGAGTCACCATAG-1 TTTGGAGTCTCACCCA-1 TTTGGTTAGATGGCGT-1\n",
       "AL627309.1 0.000000           0.000000           0.00000           \n",
       "AL669831.5 0.000000           4.286483           0.00000           \n",
       "FAM87B     0.000000           0.000000           0.00000           \n",
       "LINC00115  4.040861           0.000000           5.81081           \n",
       "FAM41C     0.000000           0.000000           0.00000           \n",
       "NOC2L      0.000000           0.000000           0.00000           \n",
       "           TTTGGTTGTACCCAGC-1 TTTGGTTGTTACTCAG-1 TTTGTTGAGCTAGAGC-1\n",
       "AL627309.1 0.000000           0                  0.000000          \n",
       "AL669831.5 0.000000           0                  4.220721          \n",
       "FAM87B     0.000000           0                  0.000000          \n",
       "LINC00115  0.000000           0                  4.906497          \n",
       "FAM41C     0.000000           0                  0.000000          \n",
       "NOC2L      5.041668           0                  4.220721          \n",
       "           TTTGTTGCAATGAAAC-1 TTTGTTGCAGAGGGTT-1\n",
       "AL627309.1 0                  0.000000          \n",
       "AL669831.5 0                  0.000000          \n",
       "FAM87B     0                  0.000000          \n",
       "LINC00115  0                  0.000000          \n",
       "FAM41C     0                  0.000000          \n",
       "NOC2L      0                  4.216369          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(as.data.frame(balf.samples[['C100']]@assays$RNA@data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea5bf274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'A1BG'</li><li>'A1BG-AS1'</li><li>'A2M'</li><li>'A2M-AS1'</li><li>'A2ML1'</li><li>'A4GALT'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'A1BG'\n",
       "\\item 'A1BG-AS1'\n",
       "\\item 'A2M'\n",
       "\\item 'A2M-AS1'\n",
       "\\item 'A2ML1'\n",
       "\\item 'A4GALT'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'A1BG'\n",
       "2. 'A1BG-AS1'\n",
       "3. 'A2M'\n",
       "4. 'A2M-AS1'\n",
       "5. 'A2ML1'\n",
       "6. 'A4GALT'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"A1BG\"     \"A1BG-AS1\" \"A2M\"      \"A2M-AS1\"  \"A2ML1\"    \"A4GALT\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ordered.genes<-sort(rownames(balf.samples$C100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea1ad13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebdf8130",
   "metadata": {},
   "source": [
    "Finally, we apply a batch correction. The goal here is to account for sample-to-sample technical variability. \n",
    "\n",
    "At this point, we diverge from the Python preprocessing tutorial in order to leverage Seurat's built-in batch correction functions. To decrease run time, we will use reciprocal PCA instead of CCA. See https://satijalab.org/seurat/articles/integration_introduction.html and Seurat's other integration vignettes for additional details. To apply Combat as in scanpy, see commented code further below.\n",
    "\n",
    "Note, the final input matrices to Tensor-cell2cell must be non-negative. We will demonstrate workarounds to negative counts in the tensor building tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9cf54db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.var <- 'Sample.ID' # the batch variable in the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9f8006b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the HVGs for each sample separately\n",
    "balf.samples <- lapply(balf.samples, \n",
    "                      function(so) FindVariableFeatures(so, selection.method = \"vst\", nfeatures = 2000))\n",
    "                       \n",
    "# find the common HVGs across samples\n",
    "integration.features <- SelectIntegrationFeatures(object.list = balf.samples)\n",
    "\n",
    "                       \n",
    "# # to use CCA instead of reciprocal PCA, follow lines 10-12, instead of lines 14-22\n",
    "# # find the integration anchors\n",
    "# integration.anchors <- FindIntegrationAnchors(object.list = balf.samples, \n",
    "#                                               anchor.features = integration.features)    \n",
    "                       \n",
    "# calculate PCA on each sample separately\n",
    "balf.samples <- lapply(X = balf.samples, FUN = function(x) {\n",
    "    x <- ScaleData(x, features = integration.features, verbose = F)\n",
    "    x <- RunPCA(x, features = integration.features, verbose = F)\n",
    "})\n",
    "\n",
    "# find the integration anchors\n",
    "integration.anchors <- FindIntegrationAnchors(object.list = balf.samples, \n",
    "                                              anchor.features = integration.features, reduction = \"rpca\")\n",
    "\n",
    "# do the batch correction\n",
    "balf.corrected <- IntegrateData(anchorset = integration.anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "91daf6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2000 top variable features were already calculated\n",
    "\n",
    "# get PCA to 100 PCs\n",
    "balf.corrected <- ScaleData(balf.corrected, verbose = F)\n",
    "balf.corrected <- RunPCA(balf.corrected, npcs = 100, verbose = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4395bdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "An object of class Seurat \n",
       "24900 features across 63102 samples within 2 assays \n",
       "Active assay: integrated (2000 features, 2000 variable features)\n",
       " 1 other assay present: RNA\n",
       " 1 dimensional reduction calculated: pca"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "balf.corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b7bac1",
   "metadata": {},
   "source": [
    "Do the batch correction using Combat. This most closely emulated the steps taken in the scanpy tutorial, though there are still differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "20ef0c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # merge the balf samples\n",
    "\n",
    "# # note, this is less stringent than scanpy's concat method and will retain all features\n",
    "# balf.corrected<-merge(x = balf.samples[[1]], y = balf.samples[2:length(balf.samples)], \n",
    "#                       add.cell.ids = names(balf.samples), merge.data = TRUE)\n",
    "\n",
    "\n",
    "# # prepare batch covariate\n",
    "# batch<-balf.corrected@meta.data[[batch.var]]\n",
    "# names(batch)<-row.names(balf.corrected@meta.data)\n",
    "# batch<-as.factor(batch)\n",
    "\n",
    "# # do the batch correction\n",
    "# com <- ComBat(dat=balf.corrected@assays$RNA@data, batch=batch)\n",
    "\n",
    "# # store the batch corrected matrix in the scale.data slot\n",
    "# balf.corrected@assays$RNA@scale.data<-com\n",
    "\n",
    "# # get the top 2000 highly variable genes\n",
    "# balf.corrected<-FindVariableFeatures(balf.corrected, nfeatures=2000)\n",
    "\n",
    "# # get PCA to 100 PCs, calculated on batch corrected matrix\n",
    "# RunPCA(balf.corrected, features=VariableFeatures(balf.corrected), npcs=100, \n",
    "#        assay = 'RNA', slot = 'scale.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71570ba",
   "metadata": {},
   "source": [
    "Finally, we can convert this batch-correct Seurat object to an AnnData object using SeuratDisk (see https://mojaveazure.github.io/seurat-disk/articles/convert-anndata.html for details). The resultant h5ad file should contain the same information as the saved h5ad file in the Python tutorial at the end of tutorial 01A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c0e9be3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating h5Seurat file for version 3.1.5.9900\n",
      "\n",
      "Adding counts for RNA\n",
      "\n",
      "Adding data for RNA\n",
      "\n",
      "No variable features found for RNA\n",
      "\n",
      "No feature-level metadata found for RNA\n",
      "\n",
      "Adding data for integrated\n",
      "\n",
      "Adding scale.data for integrated\n",
      "\n",
      "Adding variable features for integrated\n",
      "\n",
      "No feature-level metadata found for integrated\n",
      "\n",
      "Adding cell embeddings for pca\n",
      "\n",
      "Adding loadings for pca\n",
      "\n",
      "No projected loadings for pca\n",
      "\n",
      "Adding standard deviations for pca\n",
      "\n",
      "No JackStraw data for pca\n",
      "\n",
      "Validating h5Seurat file\n",
      "\n",
      "Adding scale.data from integrated as X\n",
      "\n",
      "Adding data from integrated as raw\n",
      "\n",
      "Transfering meta.data to obs\n",
      "\n",
      "Adding dimensional reduction information for pca\n",
      "\n",
      "Adding feature loadings for pca\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out.path = '/data3/hratch/c2c_general/'\n",
    "SaveH5Seurat(balf.corrected, filename = paste0(out.path, 'Rbatch_corrected_balf_covid.h5Seurat'))\n",
    "Convert(paste0(out.path, 'Rbatch_corrected_balf_covid.h5Seurat'), dest = \"h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b1138",
   "metadata": {},
   "source": [
    "The .h5ad file, named below, can be read into scanpy using scanpy.read_h5ad(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1333c4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"/data3/hratch/c2c_general/Rbatch_corrected_balf_covid.h5ad\"\n"
     ]
    }
   ],
   "source": [
    "filename=paste0(out.path, 'Rbatch_corrected_balf_covid.h5ad')\n",
    "print(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [conda env:FDA_collab]",
   "language": "R",
   "name": "conda-env-FDA_collab-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
