{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d94b8e4a",
   "metadata": {},
   "source": [
    "For use with Tensor-cell2cell, we want a dataset that represents >2 contexts. We also want a dataset that contains [replicates](https://www.nature.com/articles/nmeth.3091). Replicates will allow us to ensure that the output factors are not simply due to technical effects (i.e., a factor with high loadings for just one replicate in the context dimension). We will use a [BALF COVID dataset](https://doi.org/10.1038/s41591-020-0901-9), which contains 12 samples associated with \"Healthy Control\", \"Moderate\", or \"Severe\" COVID contexts. This dataset does not contain technical replicates since each sample was taken from a different patient, but each sample associated with a context is a biological replicate. \n",
    "\n",
    "[Batch correction](https://www.nature.com/articles/s41592-018-0254-1) removes technical variation while preserving biological variation between samples. We can reasonably assume that the biological variation in samples between contexts will be greater than that of those within contexts after using appropriate batch correction to remove technical variation. Thus, we expect Tensor-cell2cell to capture overall communication trends differing between contexts and can then assess that output factors aren't simply due to technical effects by checking that the output factors have similar loadings for biological replicates and do not have  high loadings for just one sample in the context dimension. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a3488",
   "metadata": {},
   "source": [
    "Finally, we apply a batch correction. The goal here is to account for sample-to-sample technical variability. In this case, we show Combat since it is built in with scanpy. \n",
    "\n",
    "Note, the final input matrices to Tensor-cell2cell must be non-negative. We will demonstrate workarounds to negative counts in the tensor building tutorial. \n",
    "\n",
    "See 10.1186/s13619-020-00041-9 for a benchmarking of Scanpy's batch correction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6024ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_var = 'Sample_ID' # the batch variable in the metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bafd631",
   "metadata": {},
   "source": [
    "Batch correction using combat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e123833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the balf_samples\n",
    "balf_corrected = sc.concat(balf_samples.values())\n",
    "balf_corrected.obs_names_make_unique()\n",
    "\n",
    "# store log(1+CPM) values in \"raw\" attribute\n",
    "balf_corrected.raw = balf_corrected \n",
    "\n",
    "# do the batch correction\n",
    "sc.pp.combat(balf_corrected, key = batch_var) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981ff3d",
   "metadata": {},
   "source": [
    "At some point in the pipeline, we must account for batch. Batch-correction is important since Tensor-cell2cell considers multiple balf_samples to extract context-dependent patterns, and we want to make sure we are capturing true biological signals rather than sample-specific differences due to technical variability. \n",
    "\n",
    "Ideally, we can use single-cell RNAseq batch correction methods. There are a few potential problems with this approach:\n",
    "\n",
    "1) Batch correction methods often return a matrix in a reduced space and thus does not have the original gene features included, which is needed for LR scoring (see [Table 1](https://academic.oup.com/nargab/article/4/1/lqac022/6548822)).\n",
    "\n",
    "2) Some cell-cell communication tools expect data in other formats, such as log(1+CPM)\n",
    "\n",
    "3) Batch correction methods that do return gene counts often return negative counts which can result in negative LR scores. Negative values in the tensor can bias non-negative TCD, the main algorithm used in Tensor-cell2cell.  \n",
    "\n",
    "In this tutorial, and its companion 01B for R users, we will show pre-processing from raw counts to batch corrected counts. Problem 1 can simply be dealt with by only using batch correction methods that return the original gene features. Problem 2-3 will be discussed further in Tutorials XXX. Essentially, Problems 2-3 can both be dealth with by instead directly introducing a technical covariate to account for batch directly to the decomposition. Problem 3 can also be dealt with either by masking negative values or using a TCD approach that does not have a non-negative constraint. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8225975",
   "metadata": {},
   "source": [
    "The next two cells, unused, show examples of other methods for batch correction . See https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html for more tutorials on batch correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77dc058",
   "metadata": {},
   "source": [
    "Batch correction with scanorama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d86499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scanorama\n",
    "\n",
    "# # merge all the balf_samples into a single object\n",
    "# balf_log = sc.concat(balf_samples.values())\n",
    "# balf_log.obs_names_make_unique()\n",
    "\n",
    "# # correct with scanorama\n",
    "# balf_corrected = scanorama.correct_scanpy(adatas=list(balf_samples.values()), return_dimred=False)\n",
    "\n",
    "# # aggregate into one object\n",
    "# balf_corrected = sc.concat(balf_corrected) \n",
    "# balf_corrected.obs_names_make_unique()\n",
    "\n",
    "# # store log(1+CPM) values in \"raw\" attribute\n",
    "# balf_corrected.raw = balf_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e248c6e3",
   "metadata": {},
   "source": [
    "Batch correction using a simple linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf6bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # merge the balf_samples\n",
    "# balf_corrected = sc.concat(balf_samples.values())\n",
    "# balf_corrected.obs_names_make_unique()\n",
    "\n",
    "# # store log(1+CPM) values in \"raw\" attribute\n",
    "# balf_corrected.raw = balf_corrected\n",
    "\n",
    "# # do the batch correction\n",
    "# sc.pp.regress_out(balf_corrected, keys = batch_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5737d8",
   "metadata": {},
   "source": [
    "Calculate a PCA manifold on the batch-corrected counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c301589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top 2000 highly variable genes\n",
    "sc.pp.highly_variable_genes(balf_corrected, n_top_genes = 2000)\n",
    "\n",
    "# get PCA to 100 PCs\n",
    "sc.tl.pca(balf_corrected, use_highly_variable = True, svd_solver='arpack', random_state = seed, \n",
    "         n_comps = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017fbf07",
   "metadata": {},
   "source": [
    "The final \"balf_corrected\" AnnData object has the following attributes:\n",
    "1) X: batch-correct counts matrix (preferably non-negative) <br>\n",
    "2) obs: cell metadata that includes the cell group (cluster or type), Sample ID, and Context <br>\n",
    "3) raw: log(1+CPM) normalized AnnData object <br>\n",
    "4) obsm['X_pca']: the cell manifold \n",
    "\n",
    "Regardless of the preprocessing pipeline used, these four pieces of information will be necessary for some parts of the Tensor-cell2cell analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1d22c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Dict\n",
    "# def split_adata(adata, sample_col = 'Sample_ID'):\n",
    "#     \"\"\"Split an AnnData object with corrected counts into its respective balf_samples.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     adata : AnnData\n",
    "#         merged AnnData object across balf_samples (see sc.concat)\n",
    "#     sample_col : str, optional\n",
    "#         the metadata (adata.obs) column specifying the balf_samples, by default 'Sample_ID'\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     balf_samples : Dict[str, AnnData]\n",
    "#         the set of AnnData objects corresponding to each sample\n",
    "#     \"\"\"\n",
    "    \n",
    "#     balf_samples = {sample: adata[adata.obs[adata.obs[sample_col] == sample].index] for sample in adata.obs[sample_col].unique()}\n",
    "#     return balf_samples\n",
    "\n",
    "\n",
    "# balf_corrected_split = split_adata(adata=balf_corrected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
